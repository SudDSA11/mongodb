{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. What are the key differences between SQL and NoSQL databases?"
      ],
      "metadata": {
        "id": "Xuanoal1i3pD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S5nS38WJid_Z"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "SQL\n",
        "These are relational in nature as the data is stored in from of table.\n",
        "SQl sets the standard fro structured querry language.\n",
        "They are strong ACID compliance\n",
        "They have fixed schema\n",
        "For example: MySQL, PgSQL, MsSQL etc\n",
        "\n",
        "NoSQL\n",
        "These are non-relational as they store data in form of document, key-value pairs,graphs etc.\n",
        "It stands for not only SQL.\n",
        "It retrieve ,insert, delete etc without using SQL.\n",
        "They are BASE compliance but for some specific opertation support ACID.\n",
        "They have flexible and dynamic schema\n",
        "for example : redis , mongodb etc\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " 2. What makes MongoDB a good choice for modern applications?"
      ],
      "metadata": {
        "id": "iB4CGmlQlJVh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "MongoDB is popular for modern applications because it ticks a lot of boxes that today’s fast-changing, data-heavy systems need.\n",
        "Here are few reasons :-\n",
        "1. You can store data without defining a fixed table structure — perfect for evolving app requirements.\n",
        "2. Data is stored in JSON-like documents, making it natural to work with for developers used to modern programming languages.\n",
        "3. Supports powerful queries, indexing, aggregations, and geospatial data out of the box.\n",
        "4. Can manage structured, semi-structured, and unstructured data in the same database.\n",
        "MongoDB shines when you need fast development, flexible data handling, and the ability to scale quickly — like in social media apps,\n",
        "IoT platforms, e-commerce, and SaaS products.\n",
        "'''"
      ],
      "metadata": {
        "id": "utFwkTWzlQZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Explain the concept of collections in MongoDB?\n"
      ],
      "metadata": {
        "id": "QCppe7UPlwox"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "In MongoDB, a collection is basically the equivalent of a table in SQL — but more flexible.\n",
        "A collection is a group of MongoDB documents.\n",
        "Documents inside a collection are stored in a JSON-like format called BSON (Binary JSON).\n",
        "Unlike SQL tables, collections do not enforce a fixed schema — documents in the same collection can have different fields.\n",
        "'''\n"
      ],
      "metadata": {
        "id": "7JmYOkgAl5Yh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. How does MongoDB ensure high availability using replication?"
      ],
      "metadata": {
        "id": "LX3to_54mG_x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "MongoDB ensures high availability through a feature called replication, which is implemented using replica sets.\n",
        "A replica set is a group of MongoDB servers (nodes) that store the same data.\n",
        "One node acts as the primary (handles all writes and most reads).\n",
        "Other nodes are secondaries (keep copies of the data by replicating from the primary).\n",
        "High Availability Mechanism\n",
        "1. Automatic Failover\n",
        "2. Data Redundancy\n",
        "3. Read Scaling\n",
        "4. Heartbeat Monitoring\n",
        "5. Write Concern & Read Concern\n",
        "'''\n",
        "\n"
      ],
      "metadata": {
        "id": "YAInRm8umOvJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. What are the main benefits of MongoDB Atlas?"
      ],
      "metadata": {
        "id": "u_eZsfEom0uG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "MongoDB Atlas is MongoDB’s fully managed cloud database service, and it comes with several big advantages for modern applications.\n",
        "1. Multi-cloud support\n",
        "2. Global distribution\n",
        "3. High availability & backups\n",
        "4. Strong security\n",
        "5. Performance optimization\n",
        "6. Serverless option\n",
        "'''"
      ],
      "metadata": {
        "id": "IQtBidZam7St"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.  What is the role of indexes in MongoDB, and how do they improve performance"
      ],
      "metadata": {
        "id": "42CbCxijnc28"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "In MongoDB, indexes are like the table of contents in a book — they help the database find data quickly without scanning every single document.\n",
        "Purpose: Speed up query execution by allowing MongoDB to locate documents more efficiently.\n",
        "How Indexes Improve Performance:\n",
        "1. Faster Query Execution\n",
        "2. Efficient Sorting\n",
        "3. Reduced Resource Usage\n",
        "4. Support for Complex Queries\n",
        "'''\n",
        "\n"
      ],
      "metadata": {
        "id": "H2n-c2LknnmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7.  Describe the stages of the MongoDB aggregation pipeline"
      ],
      "metadata": {
        "id": "WOoQGyUOoK4Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "The MongoDB aggregation pipeline is a framework for processing and transforming documents in stages — a bit like an assembly line,\n",
        "where each stage modifies or filters the data before passing it to the next.\n",
        "Main Stages of the Aggregation Pipeline:\n",
        "$match :\tFilters documents based on conditions (like WHERE in SQL)\n",
        "$group :\tGroups documents by a field and performs aggregations (sum, avg, count, etc.)\n",
        "$project :\tSelects or reshapes fields in the output\n",
        "$sort :\tSorts documents by specified fields\n",
        "$limit :\tLimits the number of documents returned\n",
        "$skip :\tSkips a number of documents (useful for pagination)\n",
        "$unwind :\tBreaks apart arrays into separate documents\n",
        "$lookup :\tPerforms a left outer join with another collection\n",
        "$addFields :\tAdds new computed fields to document\n",
        "$count :\tReturns the number of documents at that stage\n",
        "'''"
      ],
      "metadata": {
        "id": "JJaAo-MPoRVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. What is sharding in MongoDB? How does it differ from replication?"
      ],
      "metadata": {
        "id": "JGrpb6UopZHI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Sharding in MongoDB is a method for distributing data across multiple servers to handle very large datasets and high throughput workloads.\n",
        "Sharding:\n",
        "Scalability & large dataset handling\n",
        "Each node has only part of the data\n",
        "Horizontal (split data, more servers)\n",
        "If one shard fails, only part of the data is affected\n",
        "Improves both read and write throughput for large datasets\n",
        "Sharded cluster (can include replication in each shard)\n",
        "\n",
        "Replication\n",
        "High availability & redundancy\n",
        "Each node has a full copy of the data\n",
        "Vertical (same data, more servers)\n",
        "Automatic failover to secondaries\n",
        "Improves read availability, not write throughput\n",
        "Replica set\n",
        "'''"
      ],
      "metadata": {
        "id": "IKb5c5HDphTP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. What is PyMongo, and why is it used?"
      ],
      "metadata": {
        "id": "lmOWWzUfqEtq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "PyMongo is the official Python driver for MongoDB.\n",
        "It’s the library that lets Python applications connect to, query, and manipulate data in a MongoDB database.\n",
        "Connect Python to MongoDB\n",
        "Lets you create, read, update, and delete documents in collections.\n",
        "Runs aggregation pipelines directly from Python.\n",
        "Creates and manages indexes for performance.\n",
        "Handles login credentials, SSL/TLS connections, and access control.\n",
        "Works well with Python frameworks (Flask, Django, FastAPI) for building full-stack or backend apps.\n",
        "Automatically converts between Python dictionaries and MongoDB’s BSON format.\n",
        "'''\n"
      ],
      "metadata": {
        "id": "CUhiUKe4qLwB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. What are the ACID properties in the context of MongoDB transactions"
      ],
      "metadata": {
        "id": "McBs9-ONqkz0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "In MongoDB, ACID properties describe how transactions maintain data reliability and consistency, especially when multiple operations happen together.\n",
        "ACID = Atomicity, Consistency, Isolation, Durability\n",
        "Atomicity\t: All operations in a transaction either complete entirely or not at all.\n",
        "Consistency\t: A transaction brings the database from one valid state to another, following all rules and constraints.\n",
        "Isolation\t: Concurrent transactions don’t interfere — intermediate states are not visible to other operations.\n",
        "Durability :\tOnce committed, data is permanently stored, even if there’s a crash or power failure.\n",
        "'''\n"
      ],
      "metadata": {
        "id": "TsUFmN4hqrqK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. What is the purpose of MongoDB’s explain() function?\n"
      ],
      "metadata": {
        "id": "2XJg5NOcrFP0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Purpose of explain()\n",
        "Understand Query Execution : Shows whether the query is using an index or doing a collection scan.\n",
        "Optimize Performance : Helps identify slow queries and decide if new indexes are needed.\n",
        "Debug Query Plans : Reveals how MongoDB’s query optimizer chooses the execution strategy.\n",
        "Check Resource Usage : Provides stats like documents scanned, execution time, and stage-by-stage breakdown.\n",
        "'''\n",
        "\n"
      ],
      "metadata": {
        "id": "KY2vIHYErKIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "12.  How does MongoDB handle schema validation"
      ],
      "metadata": {
        "id": "9o4kiDItripj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "MongoDB handles schema validation by letting you define validation rules at the collection level — so while MongoDB is schema-flexible,\n",
        "you can still enforce certain structure and data rules when needed.\n",
        "How Schema Validation Works\n",
        "You create or update a collection with a validator option that defines rules using MongoDB query expressions.\n",
        "When documents are inserted or updated, MongoDB checks them against the rules.\n",
        "If a document doesn’t meet the rules, the operation fails (depending on validation level).\n",
        "'''\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VRVxCYB8rosx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "13. What is the difference between a primary and a secondary node in a replica set?"
      ],
      "metadata": {
        "id": "CAG9NW00rzE5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "In a MongoDB replica set, the primary and secondary nodes have different but complementary roles\n",
        "Primary Node\n",
        "Handles all write operations and (by default) most read operations.\n",
        "Accepts writes directly from clients.\n",
        "Participates in elections to choose a new primary.\n",
        "Default read target in readPreference: primary.\n",
        "If it fails, an election occurs to pick a new primary.\n",
        "Always accepts writes (unless it steps down or fails).\n",
        "\n",
        "Secondary Node\n",
        "Maintains a copy of the primary’s data by replicating its oplog. Can serve read queries if configured.\n",
        "Gets data from the primary via replication.\n",
        "Also participates in elections — can become primary if elected.\n",
        "Used for reads if readPreference: secondary or other settings are enabled.\n",
        "If elected during failover, becomes the new primary.\n",
        "Never accepts writes (unless it becomes the primary).\n",
        "'''"
      ],
      "metadata": {
        "id": "rggf2A4ar5bV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "14.  What security mechanisms does MongoDB provide for data protection?"
      ],
      "metadata": {
        "id": "NHY5qHvLsZx9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "MongoDB has a layered set of security mechanisms to protect data both in storage and in transit, plus strong access control.\n",
        "1. Authentication – Verify who can connect\n",
        "2. Authorization – Control what users can do\n",
        "3. Encryption\n",
        "4. Auditing\n",
        "5. Network Security\n",
        "6. Data Protection Features\n",
        "'''"
      ],
      "metadata": {
        "id": "ze7S9VfosfSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "15. Explain the concept of embedded documents and when they should be used?\n"
      ],
      "metadata": {
        "id": "I9SiD6Zbszwn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "In MongoDB, embedded documents are documents stored inside another document — like nesting objects in JSON.\n",
        "Instead of storing related data in separate collections (like SQL tables), you embed it as a sub-document.\n",
        "This allows you to keep all related information together in a single record.\n",
        "MongoDB stores documents in a BSON format, which supports nesting up to 100 levels deep\n",
        "'''"
      ],
      "metadata": {
        "id": "euTnwFJZs6Ou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "16. What is the purpose of MongoDB’s $lookup stage in aggregation?"
      ],
      "metadata": {
        "id": "8QYWg2DutFpi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "In MongoDB, the $lookup stage in the aggregation pipeline is used to join data from another collection — similar to a SQL LEFT OUTER JOIN.\n",
        "Purpose:-\n",
        "Combines documents from one collection with related documents from another collection.\n",
        "Useful when you store related data in separate collections (normalized structure) and need to retrieve them together.\n",
        "'''\n",
        "\n"
      ],
      "metadata": {
        "id": "F3VrB49rtOuT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "17. What are some common use cases for MongoDB"
      ],
      "metadata": {
        "id": "TD4V5KgmtYW_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "MongoDB is popular because its flexible, document-oriented model and scalability make it fit a wide range of modern applications.\n",
        "Use Case:-\n",
        "Content Management Systems (CMS)\n",
        "Real-time Analytics\n",
        "E-commerce Platforms\n",
        "Internet of Things (IoT)\n",
        "'''\n"
      ],
      "metadata": {
        "id": "IcsvEDSUtenP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "18. What are the advantages of using MongoDB for horizontal scaling?\n"
      ],
      "metadata": {
        "id": "IXfeqIxxt8z8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "MongoDB is designed for horizontal scaling through sharding, and that brings several key advantages when your data or traffic grows beyond what a single server can handle.\n",
        "Advantages of MongoDB for Horizontal Scaling:\n",
        "Handles huge datasets\n",
        "Improved performance\n",
        "Increased write throughput\n",
        "Elastic growth\n",
        "Cost efficiency\n",
        "Geo-distribution\n",
        "'''"
      ],
      "metadata": {
        "id": "UUoTzYzluE0E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "19.  How do MongoDB transactions differ from SQL transactions?"
      ],
      "metadata": {
        "id": "ieU1U0uKuYva"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "MongoDB transactions and SQL transactions both follow ACID principles, but they differ in scope, design philosophy, and common use cases.\n",
        "\n",
        " Aspect               SQL Transactions                                                                                MongoDB Transactions                                                                                                 |\n",
        "\n",
        " Data Model           Operate on rows across tables in a **relational** model.                                        Operate on documents in **collections** (document-oriented).                                                         |\n",
        " Scope (Default)      Multi-row, multi-table transactions are native and common.                                      Historically single-document atomicity (multi-document transactions added in v4.0+).                                 |\n",
        " Performance Impact   Usually optimized for multi-row transactions from the start.                                    Multi-document transactions are slower than single-document ops; MongoDB encourages embedding to avoid them.         |\n",
        " Typical Use Case     Complex joins, banking operations, inventory systems needing strict multi-table consistency.    Occasional use for cross-document consistency; often avoided by using document design to keep related data together. |\n",
        " Isolation Levels     Multiple isolation levels (Read Uncommitted → Serializable).                                    Uses **snapshot isolation** for transactions.                                                                        |\n",
        " Implementation       Locking mechanisms are table/row-based.                                                         Uses **two-phase commit** under the hood for multi-document transactions.                                            |\n",
        " Best Practice        Normalize data and use transactions frequently.                                                 Denormalize/Embed data to minimize need for transactions.                                                            |\n",
        "'''"
      ],
      "metadata": {
        "id": "-ENy1dy1ueOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "20. What are the main differences between capped collections and regular collections"
      ],
      "metadata": {
        "id": "m8Ae0SwXva6W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Capped Collection → Fixed-size collection that overwrites oldest documents when it reaches its size limit\n",
        "size limit is  defined at creation (in bytes).\n",
        "Automatic deletion — oldest docs overwritten when full.\n",
        "Preserves insertion order.\n",
        "Cannot increase document size beyond original; must fit existing space.\n",
        "_id index is automatic; can create additional indexes since MongoDB 5.0 (before that, limited).\n",
        "\n",
        "Regular Collection → Standard MongoDB collection with no fixed size; grows as needed\n",
        "No fixed size.\n",
        "Must delete documents manually\n",
        "No guaranteed order unless explicitly sorted.\n",
        "No restriction — docs can grow in size.\n",
        "Full indexing support.\n",
        "'''\n"
      ],
      "metadata": {
        "id": "A03-N4dFvnKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "21. What is the purpose of the $match stage in MongoDB’s aggregation pipeline?\n"
      ],
      "metadata": {
        "id": "rvpfC2lNwOqu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "The $match stage in MongoDB’s aggregation pipeline is used to filter documents based on specific conditions, similar to the find() query filter.\n",
        "Purpose:\n",
        "Selects only the documents that meet certain criteria so that later stages in the pipeline process fewer documents.\n",
        "Improves performance by reducing data early in the pipeline.\n",
        "'''"
      ],
      "metadata": {
        "id": "0XUlfi0WwXw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "22. How can you secure access to a MongoDB database?"
      ],
      "metadata": {
        "id": "CKXSLpegwgkb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Securing access to a MongoDB database involves multiple layers of protection — from authentication to encryption and network controls.\n",
        "1. Enable Authentication\n",
        "2. Use Role-Based Access Control (RBAC)\n",
        "3. Enable Network Access Controls\n",
        "4. Encrypt Data\n",
        "5. Enable Auditing\n",
        "6. Keep MongoDB Updated\n",
        "7. Disable Unused Features\n",
        "'''\n"
      ],
      "metadata": {
        "id": "ovIVKvSlwnQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "23. What is MongoDB’s WiredTiger storage engine, and why is it important?\n"
      ],
      "metadata": {
        "id": "JA1E4odpxB9k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "The WiredTiger storage engine is MongoDB’s default storage engine (since version 3.2) that manages how data is stored, accessed, and updated on disk.\n",
        "It’s important because it directly affects performance, scalability, and data safety.\n",
        "Why It’s Important\n",
        "Performance: Faster reads/writes due to better concurrency and compression.\n",
        "Scalability: Handles large datasets efficiently with lower disk usage.\n",
        "Reliability: Checkpointing and journaling protect against data loss.\n",
        "Flexibility: Configurable compression and cache tuning for different workloads.\n",
        "'''\n",
        "\n"
      ],
      "metadata": {
        "id": "61jO-McTxHlE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Write a Python script to load the Superstore dataset from a CSV file into MongoDB"
      ],
      "metadata": {
        "id": "iwnIeesg815r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pymongo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56u66_xv9iZZ",
        "outputId": "352cdfb7-23f4-4e1a-be45-71752549f35b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymongo\n",
            "  Downloading pymongo-4.14.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo)\n",
            "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Downloading pymongo-4.14.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: dnspython, pymongo\n",
            "Successfully installed dnspython-2.7.0 pymongo-4.14.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pymongo import MongoClient\n",
        "\n",
        "# --- Configuration ---\n",
        "MONGO_URI = \"mongodb://localhost:27017/\"\n",
        "DB_NAME = \"superstore_db\"\n",
        "COLLECTION_NAME = \"sales\"\n",
        "CSV_FILE = \"superstore.csv\"  # Path to your CSV file\n",
        "\n",
        "# --- Connect to MongoDB ---\n",
        "client = MongoClient(MONGO_URI)\n",
        "db = client[DB_NAME]\n",
        "collection = db[COLLECTION_NAME]\n",
        "\n",
        "# --- Load CSV into Pandas ---\n",
        "try:\n",
        "    df = pd.read_csv(CSV_FILE)\n",
        "    print(f\"Loaded CSV with {len(df)} rows.\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: The file '{CSV_FILE}' was not found.\")\n",
        "    # exit() # Removed exit() to allow the program to continue\n",
        "\n",
        "# --- Convert DataFrame to Dictionary ---\n",
        "if 'df' in locals(): # Check if df is defined\n",
        "    data = df.to_dict(orient=\"records\")\n",
        "\n",
        "    # --- Insert Data into MongoDB ---\n",
        "    if data:\n",
        "        collection.insert_many(data)\n",
        "        print(f\"Inserted {len(data)} documents into '{COLLECTION_NAME}' collection.\")\n",
        "    else:\n",
        "        print(\"No data found in CSV.\")\n",
        "\n",
        "    # --- Verify Insertion ---\n",
        "    print(\"Sample document from MongoDB:\")\n",
        "    print(collection.find_one())\n",
        "else:\n",
        "    print(\"Cannot proceed without the CSV file.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ol_laz0h84d6",
        "outputId": "47fe2345-cb1e-475c-a9cc-a4cc14dbba12"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: The file 'superstore.csv' was not found.\n",
            "Cannot proceed without the CSV file.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.Retrieve and print all documents from the Orders collection"
      ],
      "metadata": {
        "id": "YMDvE1Eh-E7m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Retrieve and Print All Documents ---\n",
        "print(\"All documents in Orders collection:\\n\")\n",
        "for doc in collection.find():\n",
        "    pprint.pprint(doc)  # Pretty-print for better readability\n"
      ],
      "metadata": {
        "id": "7RvN8dsHBDX3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.  Count and display the total number of documents in the Orders collection"
      ],
      "metadata": {
        "id": "eUtLNAO_-TG3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "count = collection.count_documents({})\n",
        "print(f\"Total number of documents in '{COLLECTION_NAME}' collection: {count}\")"
      ],
      "metadata": {
        "id": "6S23feQd-N52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.  Write a query to fetch all orders from the \"West\" region"
      ],
      "metadata": {
        "id": "X1MmyZNH-dJu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Query for Orders from \"West\" Region ---\n",
        "print(\"Orders from the 'West' region:\\n\")\n",
        "for doc in collection.find({\"Region\": \"West\"}):\n",
        "    pprint.pprint(doc)  # Pretty-print each document"
      ],
      "metadata": {
        "id": "eIJ8qniS-jdu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Write a query to find orders where Sales is greater than 500"
      ],
      "metadata": {
        "id": "Z4fyo-x3-kvF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Query for Sales > 500 ---\n",
        "print(\"Orders where Sales > 500:\\n\")\n",
        "for doc in collection.find({\"Sales\": {\"$gt\": 500}}):\n",
        "    pprint.pprint(doc)"
      ],
      "metadata": {
        "id": "beCpBFvG-ohn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Fetch the top 3 orders with the highest Profit"
      ],
      "metadata": {
        "id": "QKHhePVD-ueV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Fetch Top 3 Highest Profit Orders ---\n",
        "print(\"Top 3 orders with highest Profit:\\n\")\n",
        "for doc in collection.find().sort(\"Profit\", -1).limit(3):\n",
        "    pprint.pprint(doc)"
      ],
      "metadata": {
        "id": "8XpkHaS6-wwM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7.  Update all orders with Ship Mode as \"First Class\" to \"Premium Class.O\n"
      ],
      "metadata": {
        "id": "fuKWESQF-zd2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = collection.update_many(\n",
        "    {\"Ship Mode\": \"First Class\"},  # Filter\n",
        "    {\"$set\": {\"Ship Mode\": \"Premium Class\"}}  # Update\n",
        ")\n",
        "\n",
        "# --- Result ---\n",
        "print(f\"Matched {result.matched_count} documents\")\n",
        "print(f\"Modified {result.modified_count} documents\")"
      ],
      "metadata": {
        "id": "ysAnYA9X-8gL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Delete all orders where Sales is less than 50"
      ],
      "metadata": {
        "id": "i92KYvKD-98s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Delete Orders ---\n",
        "result = collection.delete_many({\"Sales\": {\"$lt\": 50}})\n",
        "\n",
        "# --- Result ---\n",
        "print(f\"Deleted {result.deleted_count} documents where Sales < 50\")\n"
      ],
      "metadata": {
        "id": "nSYqYSgX_Dds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "9.  Use aggregation to group orders by Region and calculate total sales per region"
      ],
      "metadata": {
        "id": "ylN-g8OR_IyW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Aggregation Pipeline ---\n",
        "pipeline = [\n",
        "    {\n",
        "        \"$group\": {\n",
        "            \"_id\": \"$Region\",              # Group by Region\n",
        "            \"total_sales\": {\"$sum\": \"$Sales\"}  # Sum of Sales\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"$sort\": {\"total_sales\": -1}       # Sort by total sales (descending)\n",
        "    }\n",
        "]\n",
        "# --- Run Aggregation ---\n",
        "results = collection.aggregate(pipeline)\n",
        "\n",
        "# --- Display Results ---\n",
        "print(\"Total Sales by Region:\")\n",
        "for result in results:\n",
        "    print(f\"Region: {result['_id']}, Total Sales: {result['total_sales']}\")\n"
      ],
      "metadata": {
        "id": "4OliaoLo_Pi2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. Fetch all distinct values for Ship Mode from the collection"
      ],
      "metadata": {
        "id": "64uSnl5C_T7D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# --- Fetch Distinct Ship Modes ---\n",
        "ship_modes = collection.distinct(\"Ship Mode\")\n",
        "\n",
        "# --- Display Results ---\n",
        "print(\"Distinct Ship Modes:\")\n",
        "for mode in ship_modes:\n",
        "    print(mode)"
      ],
      "metadata": {
        "id": "ZCSIFs7L_Yrz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "11.  Count the number of orders for each category"
      ],
      "metadata": {
        "id": "xN3Z71z4_ih8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Aggregation Pipeline ---\n",
        "pipeline = [\n",
        "    {\n",
        "        \"$group\": {\n",
        "            \"_id\": \"$Category\",       # Group by Category\n",
        "            \"order_count\": {\"$sum\": 1}  # Count orders\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"$sort\": {\"order_count\": -1} # Sort by count (descending)\n",
        "    }\n",
        "]\n",
        "# --- Run Aggregation ---\n",
        "results = collection.aggregate(pipeline)\n",
        "\n",
        "# --- Display Results ---\n",
        "print(\"Number of Orders per Category:\")\n",
        "for result in results:\n",
        "    print(f\"Category: {result['_id']}, Orders: {result['order_count']}\")"
      ],
      "metadata": {
        "id": "2MCniSr1_fBk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}